# Geo RAG — Streamlit Retrieval-Augmented Generation Demo

A compact, portfolio-ready Retrieval-Augmented Generation (RAG) demo built with Streamlit. Geo RAG demonstrates a full RAG pipeline that retrieves geo-tagged documents from a persisted Chroma vector database and generates per-place natural-language answers with a local LLM. Results are presented on an interactive Folium map with marker popups containing LLM-generated summaries.

## What this project shows

- A reproducible RAG flow: query → retrieval → LLM prompt → generated answer.
- A persisted Chroma vector store seeded from `geo_knowledge.csv` (or your own dataset).
- Sentence-Transformers embeddings used to vectorize documents for similarity search.
- Local LLM integration (Ollama/phi-3 or any provider) with defensive call wrappers to handle different call shapes.
- Folium map integration with marker popups that display per-place generated answers and an animated map focus when a single place is selected.

## Features

- Enter-to-submit search box (press Enter to run the query).
- Robust retrieval and LLM invocation fallbacks for portability across LangChain versions and local wrappers.
- Per-place LLM-generated popups rather than raw DB text.
- Map animation: `flyTo` when one place is returned, `fitBounds` when many results are returned.
- Styled for portfolio presentation (CartoDB Positron theme, white popups, black text).

## Quick start

Requirements

- Python 3.11
- Optional: local Ollama server or other LLM endpoint

Create and activate venv, then install:

```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

If you already have a `geo_db/` folder (a persisted Chroma DB), you can run the app directly. Otherwise run the vector creation notebook:

- `rag_vector_creation.ipynb` — creates vectors and persists a Chroma directory at `geo_db/`.

Run the Streamlit app:

```bash
streamlit run app.py
```

Open the printed local address (usually http://localhost:8501).

## Files and structure

- `app.py` — Streamlit application and RAG flow.
- `geo_knowledge.csv` — source content used to seed the Chroma DB.
- `geo_db/` — persisted Chroma directory created by the vectorization notebook.
- `rag_vector_creation.ipynb` — Notebook to create vectors and persist them.
- `data/` — supporting data such as `worldcities.csv`.
- `requirements.txt` — Python dependencies.

## How to adapt / run without Ollama

If you cannot use an Ollama local LLM, adapt the LLM wrapper inside `app.py` to call OpenAI or another local LLM binding. The code includes a `call_llm` helper that attempts multiple call shapes (`callable`, `.predict`, `.generate`) and normalizes output to text.

## Where to paste screenshots (recommended)

Create a `screenshots/` folder inside the `geo-rag/` directory and paste demo screenshots there. Use clear, short filenames and include a small README note inside the folder with guidance.

- Recommended path: `geo-rag/screenshots/`
- Naming convention: `screenshot-01.png`, `screenshot-02.png`, `screenshot-map-results.png`, `screenshot-flow.png`
- Recommended sizes: 1200×700 (landscape) for hero/demo screenshots, and 800×1200 (portrait) for step-by-step images.

Example project tree:

```
geo-rag/
  app.py
  geo_knowledge.csv
  geo_db/        # generated by rag_vector_creation.ipynb
  rag_vector_creation.ipynb
  requirements.txt
  screenshots/
    screenshot-01.png
    screenshot-map-results.png
```

## Demo blurb (for portfolio)

"Geo RAG — a compact Streamlit demo that combines Chroma vector search, sentence-transformers embeddings, and a local LLM to produce map-based, per-place generated summaries. Built with defensive retrieval and LLM wrappers to remain robust across LangChain and local LLM wrapper changes."

## One-liner

"Geo RAG — Streamlit demo using Chroma + sentence-transformers + local LLM to build a map-based RAG demo with per-place generated summaries."

## Limitations & next steps

- One LLM call per place is simple and clear, but slow for many results. Consider batching or caching.
- The project uses community Ollama wrappers that may need updates with LangChain; prefer `langchain-ollama` or your provider's official adapter.
- Add file-based caching for per-place summaries to speed repeated queries.
- Add a small CI to validate vector creation and retrieval.

## License

Add a `LICENSE` file if you want to open-source this project. MIT is a common permissive choice.

---

If you'd like, I can also:

- Add the `screenshots/` folder and a tiny `screenshots/README.md` with paste instructions (I can create placeholders).
- Produce a short GIF and provide guidance for recording a demo.
- Tailor the README tone (concise vs detailed) for a resume or portfolio page.

Tell me which extra items you'd like and I'll add them.
